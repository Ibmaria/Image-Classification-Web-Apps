{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWuYK7pC4_QR"
   },
   "outputs": [],
   "source": [
    "#[1]*10**10 #get more ram quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GILelQwk7SN4",
    "outputId": "5f7bf904-1cba-4aa5-94b8-3447ffeaf115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
      "/gdrive/My Drive/CDIP Dataset\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    " \n",
    "drive.mount('/gdrive')\n",
    "# the project's folder\n",
    "%cd /gdrive/'My Drive'/CDIP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bGzGQN6oEtQ9",
    "outputId": "7aed3ccc-425a-4134-8417-f16ffc996a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#I unzip images folder\n",
    "from zipfile import ZipFile\n",
    "filename='final.zip'\n",
    "with ZipFile(filename,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Co9n3LcB5q_B",
    "outputId": "5129f4f7-bb8e-4630-9d5e-1604cb97b681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading https://files.pythonhosted.org/packages/17/4b/4dbd55388225bb6cd243d21f70e77cb3ce061e241257485936324b8e920f/pytesseract-0.3.6.tar.gz\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
      "Building wheels for collected packages: pytesseract\n",
      "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytesseract: filename=pytesseract-0.3.6-py2.py3-none-any.whl size=13629 sha256=966a25bcfdc8da8ff6129e800b30db60bd29e03eb8e58123fa10aef615e9a99e\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/71/72/b98430261d849ae631e283dfc7ccb456a3fb2ed2205714b63f\n",
      "Successfully built pytesseract\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "jVxQuZUm5y85",
    "outputId": "eb1226f7-7caf-41cf-e606-c7cd37a04bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  tesseract-ocr-eng tesseract-ocr-osd\n",
      "The following NEW packages will be installed:\n",
      "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
      "0 upgraded, 3 newly installed, 0 to remove and 11 not upgraded.\n",
      "Need to get 4,795 kB of archives.\n",
      "After this operation, 15.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
      "Fetched 4,795 kB in 3s (1,624 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "(Reading database ... 144600 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
      "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
      "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
      "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZ3XUbQP5a5g"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "from builtins import str\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5aXBrUB5_ys"
   },
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r'/usr/bin/tesseract'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TsGg0CSI9j7"
   },
   "outputs": [],
   "source": [
    "ensemble_paths = ['Adver/','email/','handwriten/','invoice/','letter/']\n",
    "base = '/gdrive/My Drive/CDIP Dataset/cvl/train_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2H7qTqu06N_l",
    "outputId": "c252c923-353d-4727-ee64-dbd5413772c3"
   },
   "outputs": [],
   "source": [
    "ensemble_paths = ['Adver/','email/','handwriten/','letter/']\n",
    "base = '/gdrive/My Drive/CDIP Dataset/cvl/train_data/' #traininig\n",
    "for ensemble_path in ensemble_paths:\n",
    "  imagePaths = list(paths.list_images(base +ensemble_path))\n",
    "  for image_path in imagePaths:\n",
    "    filename = image_path\n",
    "    format_ = 'txt'\n",
    "    image = Image.open(filename)\n",
    "    basename, ext = os.path.splitext(filename)\n",
    "    \n",
    "    target = basename + \".\" + format_\n",
    "    tess_output = pytesseract.image_to_string(image, lang='eng', config=\"--psm 3 --oem 1\")\n",
    "    \n",
    "    if len(tess_output)<4:\n",
    "      continue\n",
    "    with open(target, \"w\",) as fp:\n",
    "      fp.write(str(tess_output))\n",
    "    \n",
    "    \n",
    "        \n",
    "  print(\"fini\",ensemble_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0WWnT_d0797A",
    "outputId": "ab91b35c-4e1a-4537-d400-0218efc40ab1"
   },
   "outputs": [],
   "source": [
    "base = '/gdrive/My Drive/CDIP Dataset/cvl/test_data/' #traininig\n",
    "for ensemble_path in ensemble_paths:\n",
    "  imagePaths = list(paths.list_images(base +ensemble_path))\n",
    "  \n",
    "  for image_path in imagePaths:\n",
    "    filename = image_path\n",
    "    format_ = 'txt'\n",
    "    image = Image.open(filename)\n",
    "    basename, ext = os.path.splitext(filename)\n",
    "    target = basename + \".\" + format_\n",
    "    tess_output = pytesseract.image_to_string(image, lang='eng', config=\"--psm 3 --oem 1\")\n",
    "    \n",
    "    if len(tess_output)<4:\n",
    "      continue\n",
    "    with open(target, \"w\",) as fp:\n",
    "      fp.write(str(tess_output))\n",
    "    \n",
    "        \n",
    "  print(\"fini\",ensemble_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "GeqkM4wz8XSM",
    "outputId": "ac8524e4-a0a7-4428-d3c0-ff49a0402ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "406\n",
      "388\n",
      "346\n",
      "total Files empty 0\n"
     ]
    }
   ],
   "source": [
    "#check if text file contain empty doc\n",
    "ensemble_paths = ['Adver','email','handwriten','letter']\n",
    "dict={}\n",
    "files_vide=[]\n",
    "\n",
    "include_extension =['txt']\n",
    "for label in ensemble_paths:\n",
    "  base ='/gdrive/My Drive/CDIP Dataset/cvl/test_data/'+label   #train_data\n",
    "  files = [fn for fn in os.listdir(base) if any(fn.endswith(ext) for ext in include_extension)]\n",
    "\n",
    "  for  file in files:\n",
    "    \n",
    "    fr = open(base+'/'+file,encoding='utf-8',errors='ignore')\n",
    "    root = file.split('.')[0]\n",
    "    \n",
    "    text =fr.read().replace('\\n','').split()\n",
    "    if len(text) < 1:\n",
    "      files_vide.append(file)\n",
    "      \n",
    "            \n",
    "       \n",
    "        \n",
    "    \n",
    "    \n",
    "print('total Files empty',len(files_vide))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z58KmA9n8t1Q"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "def remove_characters(tokens):\n",
    "  pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "  filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "  return filtered_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cAphmiLKf76Y",
    "outputId": "181def65-4735-4bc6-d55e-96fe9791e156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rDEpfAIq834D",
    "outputId": "316ddba9-0de0-46c8-cd9b-65873cf86df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "stop_words_list = stopwords.words('english')\n",
    "punctuation_list=list(string.punctuation)\n",
    "stop_punc_lists=stop_words_list+punctuation_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn74qRut6v_Z"
   },
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping):\n",
    "  contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),flags=re.IGNORECASE|re.DOTALL)\n",
    "  def expand_match(contraction):\n",
    "    match = contraction.group(0)\n",
    "    first_char = match[0]\n",
    "    expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "    expanded_contraction = first_char+expanded_contraction[1:]\n",
    "    return expanded_contraction\n",
    "  expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "  expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "  return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsxSBfx_67Wm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZepLSjG9Np2"
   },
   "outputs": [],
   "source": [
    "#remove punctuation in text data files\n",
    "ensemble_paths = ['Adver','email','handwriten','letter']\n",
    "\n",
    "files_vide=[]\n",
    "max_len=[]\n",
    "include_extension =['txt']\n",
    "for label in ensemble_paths:\n",
    "  base ='/gdrive/My Drive/CDIP Dataset/cvl/test_data/'+label\n",
    "    \n",
    "    #text files selection\n",
    "  files = [fn for fn in os.listdir(base) if any(fn.endswith(ext) for ext in include_extension)]\n",
    "  \n",
    "  for  file in files:\n",
    "    fr = open(base+'/'+file,encoding='utf-8',errors='ignore')\n",
    "    \n",
    "    text =fr.read().replace('\\n','')\n",
    "    text=text.split()\n",
    "    tokens=[token for token in text if token not in stop_punc_lists]\n",
    "    tokens=[token.lower() for token in tokens]\n",
    "    tokens = [token for token in tokens if (len(token) > 2 and len(token)<14)]\n",
    "    tokens = [token for token in tokens if not token.isdigit()]\n",
    "    \n",
    "    max_len.append(len(tokens))\n",
    "    tokens =' '.join(tokens)\n",
    "    \n",
    "    with open(base+'/'+file, \"w\") as fp:\n",
    "      fp.write(str(tokens))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j_iSm4RMkFi1",
    "outputId": "fd946c84-37c5-43cb-cbcc-82104d0ebe3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/CDIP Dataset/cvl\n"
     ]
    }
   ],
   "source": [
    "%cd /gdrive/'My Drive'/CDIP Dataset/cvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIT9ukpXjTYY"
   },
   "outputs": [],
   "source": [
    "from my_feature_selection_algo import *\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-yeEz1RHkyH6",
    "outputId": "641ecf08-e75b-47aa-c7d1-a682edf14d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "406\n",
      "388\n",
      "346\n"
     ]
    }
   ],
   "source": [
    "#Select features for each label\n",
    "ensemble_labels = ['Adver','email','handwriten','letter']\n",
    "dict_labels={}\n",
    "corpus_each_label={}\n",
    "max_len=[]\n",
    "include_extension =['txt']\n",
    "for label in ensemble_labels:\n",
    "  dict_labels[label]=[]\n",
    "  corpus_each_label[label]=[]\n",
    "  base ='/gdrive/My Drive/CDIP Dataset/cvl/final/'+label\n",
    "    \n",
    "  #text files selection\n",
    "  files = [fn for fn in os.listdir(base) if any(fn.endswith(ext) for ext in include_extension)]\n",
    "  print(len(files))\n",
    "  for file in files:\n",
    "    fr = open(base+'/'+file,encoding='utf-8',errors='ignore')\n",
    "    text =fr.read().replace('\\n','')\n",
    "    corpus_each_label[label].append(text)\n",
    "    max_len.append(len(text))\n",
    "        \n",
    "    text=text.split()\n",
    "    dict_labels[label].append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4481MK_x06JE",
    "outputId": "65383ee5-4fff-4438-b066-d083ebd57fb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.40226817878585"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGOJ7RWDsAk1"
   },
   "outputs": [],
   "source": [
    "#score each feature in each label corpus\n",
    "dict_words={}\n",
    "labels = ['Adver','email','handwriten','letter']\n",
    "for label in labels:\n",
    "  pos=label \n",
    "  corpus=corpus_each_label[pos]\n",
    "  corpus = ' '.join(corpus)\n",
    "  corpus=corpus.split()\n",
    "  corpus = np.unique(corpus)#get unique word\n",
    "  negative = list(set([pos]).symmetric_difference(set(labels)))\n",
    "#print(negative)\n",
    "  for word_corpus in corpus:\n",
    "    dict_words[word_corpus]=[]\n",
    "    tp,fn=document_positive_containing_term(pos,dict_labels,word_corpus)\n",
    "    fp,tn = document_negative_containing_term(negative,dict_labels,word_corpus)\n",
    "    pos_sample = tp + fn\n",
    "    neg_sample = fp + tn\n",
    "\n",
    "    tpr = tp / pos_sample\n",
    "    fpr = fp / neg_sample\n",
    "    # score acc2\n",
    "    score = abs(tpr -fpr)\n",
    "    #min_q=min(tpr,fpr)\n",
    "    #if min_q<=0:\n",
    "     # min_q=-1\n",
    "    #score =score/min_q\n",
    "    #else:\n",
    "     #   score=score/min_q\n",
    "        \n",
    "    #score = score/min(tpr,fpr)\n",
    "    #pos = tp + fn\n",
    "    dict_words[word_corpus].append({\"tp\":tp,\n",
    "                          \"fp\":fp,\n",
    "                          \"fn\":fn,\n",
    "                           \"tn\":tn,\n",
    "                           \"score_acc2\":score\n",
    "                                    \n",
    "                          })\n",
    "#sort the dict by acc2 score values\n",
    "  scores_sorted=sorted(dict_words.items(), key=lambda item: item[1][0]['score_acc2'],reverse=True)\n",
    "  best_features=[]\n",
    "  for best in scores_sorted:\n",
    "    best_features.append(best[0])\n",
    "  best_features =' '.join(best_features) \n",
    "  with open('/gdrive/My Drive/CDIP Dataset/cvl/best_features/'+pos+'/'+pos+'.txt','w') as f:\n",
    "    f.write(str(best_features))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "image_to_ocr_text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
